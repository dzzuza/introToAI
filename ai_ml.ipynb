{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from matplotlib import style\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import LineCollection\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading users data from multiple files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"data/procedure/\"\n",
    "\n",
    "# Reading data from multiple files\n",
    "files = []\n",
    "# r=root, d=directories, f = files\n",
    "for r, d, f in os.walk(path):\n",
    "    for file in f:\n",
    "        if '.txt' in file:\n",
    "            files.append(os.path.join(r, file))\n",
    "\n",
    "# Filtering files\n",
    "files = filter(lambda file: not file.endswith('_info.txt'), files)\n",
    "files = filter(lambda file: os.stat(file).st_size > 0, files)\n",
    "\n",
    "datas = []\n",
    "\n",
    "for f in files:\n",
    "    datas.append(pd.read_csv(f, sep='\\t', names=[\"Id\",\"Index\",\"Consistence\",\"Stimulant\",\"SoundId\",\"ImageId\",\"Widget\",\"Result\",\"Time\",\"Timestamp\"]))\n",
    "    \n",
    "data = pd.concat(datas, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering data for data (inc) and data_con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stringListToValues(result):\n",
    "    result = result.strip('[]')\n",
    "    values = (result.split(','))\n",
    "    return [float(values[0].strip()), float(values[1].strip())]\n",
    "\n",
    "# def discretization(val):\n",
    "#     if val < -0.33:\n",
    "#         return 1\n",
    "#     elif val < 0.33:\n",
    "#         return 5\n",
    "#     else:\n",
    "#         return 9\n",
    "\n",
    "# Emospace1\n",
    "data = data[data['Widget'] == 'emospace1']\n",
    "\n",
    "# Getting valence and arousal to different columns\n",
    "data['Result'] = data.Result.apply(func = stringListToValues)\n",
    "data[['valence','arousal']] = pd.DataFrame(data.Result.values.tolist(), index = data.index)\n",
    "\n",
    "#Getting consistence data before scaling\n",
    "data_con = data[data['Consistence'] == 'con']\n",
    "data_con = data_con[['valence', 'arousal', 'SoundId', 'ImageId', 'Stimulant']]\n",
    "\n",
    "# Scaling valence and arousal\n",
    "data['valence'] = data['valence'].apply(lambda it : (it * 4) + 5);\n",
    "data['arousal'] = data['arousal'].apply(lambda it : (it * 4) + 5);\n",
    "\n",
    "# Scaling with discretization valence and arousal\n",
    "# data['valence'] = data['valence'].apply(lambda it : round((it * 4) + 5, 2));\n",
    "# data['arousal'] = data['arousal'].apply(lambda it : round((it * 4) + 5, 2));\n",
    "\n",
    "# discretization valence - does not seem to make much difference\n",
    "# data['valence'] = data['valence'].apply(func = discretization)\n",
    "# data['arousal'] = data['arousal'].apply(func = discretization)\n",
    "\n",
    "# Data con to different variable\n",
    "data_minus = data[data['Stimulant'] == 'p-s-']\n",
    "data = data[data['Consistence'] == 'inc']\n",
    "data_with_minus = pd.concat([data_minus, data])\n",
    "\n",
    "# Getting only data we want\n",
    "data = data[['Id','Index','valence', 'arousal', 'SoundId', 'ImageId', 'Stimulant']]\n",
    "data_with_minus = data_with_minus[['Id','Index','valence', 'arousal', 'SoundId', 'ImageId', 'Stimulant']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Joining data for image and sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reading data frames for pictures and sounds\n",
    "df_picture = pd.read_csv('IAPS.csv', sep=';')\n",
    "df_sound = pd.read_csv('IADS2.csv', sep=';')\n",
    "\n",
    "# Now we do not take into consideration weird Picture Ids (with comma)\n",
    "df_picture = df_picture[df_picture['IAPS'].str.find(',') == -1]\n",
    "\n",
    "# Changing type - required for merge\n",
    "df_picture = df_picture.astype({'IAPS' : 'int64'})\n",
    "\n",
    "# Merging\n",
    "df_merge = pd.merge(data, df_picture, left_on='ImageId', right_on='IAPS', how='inner') # Brak dopasowań po usunięciu elementów z przecinkami w indeksie \n",
    "df_final = pd.merge(df_merge, df_sound, left_on='SoundId', right_on='Number', how='inner')\n",
    "\n",
    "# Renaming\n",
    "df_final = df_final.rename(index=str, columns={\n",
    "    \"ValenceMean_x\":\"ValMeanPic\",\n",
    "    \"ValenceMean_y\":\"ValMeanSound\",\n",
    "    'ValenceSD_x':'ValSDPic',\n",
    "    'ValenceSD_y':'ValSDSound',\n",
    "    'ArousalMean_x':'ArMeanPic',\n",
    "    'ArousalMean_y':'ArMeanSound',\n",
    "    'ArousalSD_x':'ArSDPic',\n",
    "    'ArousalSD_y':'ArSDSound'\n",
    "})\n",
    "\n",
    "# Typing\n",
    "df_final = df_final.applymap(lambda s : s.replace(',', '.') if isinstance(s, str) else s);\n",
    "df_final = df_final.astype({\n",
    "    'ValSDPic' : 'float64',\n",
    "    'ArSDPic' : 'float64',\n",
    "    'arousal' : 'float64',\n",
    "    'valence' : 'float64',\n",
    "    'ValMeanPic' : 'float64',\n",
    "    'ArMeanPic' : 'float64'\n",
    "})\n",
    "\n",
    "# Deleting NaN values if exists - no occured\n",
    "df_final.dropna(inplace=True)\n",
    "\n",
    "# Printing sample rows from final data frame\n",
    "print(\"############################# df_final.head() ##############################\\n\")\n",
    "print(df_final.head())\n",
    "print(\"\\ndf_finale.len = \",len(df_merge))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Regresji linionwej na dobrych danych "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = [[200,100,20]]\n",
    "\n",
    "for i in range(100):\n",
    "    test_data.append([i, (i*2), (i*5)])\n",
    "    test_data.append([i*800, (i*200), (i*3)])\n",
    "\n",
    "df_test = pd.DataFrame(test_data, columns = ['x', 'y', 'z'])\n",
    "\n",
    "X = np.array(df_test[['x', 'y']])\n",
    "y = np.array(df_test['z'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "clf = LinearRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "\n",
    "print(\"Linear regression accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choosing and spliting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.drop_duplicates(subset=['Id','Index'],keep=False,inplace=True)\n",
    "\n",
    "# Comments : less features - better results\n",
    "#          : reducing accuracy worsens results - the only improved case is Decision Tree with an accuracy of 1/10\n",
    "X = np.array(df_final[['ValMeanPic' , 'ValMeanSound', 'ArMeanPic', 'ArMeanSound']])\n",
    "y = np.array(df_final[['valence']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model regresji linowej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf = LinearRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "\n",
    "print(\"Linear regression accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regresja - drzewo decyzyjne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf = tree.DecisionTreeRegressor()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "\n",
    "print(\"Regression - decision tree accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf = RandomForestRegressor(n_estimators=20, random_state=0)\n",
    "clf.fit(X_train, y_train.ravel())\n",
    "\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "\n",
    "print(\"RandomForestRegressor accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVR(kernel='linear')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "\n",
    "print(\"SVR accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear regression for different feaures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [['ArMeanPic', 'arousal'], ['ArMeanSound', 'arousal'], ['ValMeanPic', 'valence'], ['ValMeanSound', 'valence']]\n",
    "\n",
    "for feature in features:\n",
    "    X_local = np.array(df_final[feature[0]])\n",
    "    y_local = np.array(df_final[feature[1]])\n",
    "\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_local[:, np.newaxis], y_local)\n",
    "\n",
    "    segments = [[[i, y_local[i]]] for i in range(len(X_local))]\n",
    "    lc = LineCollection(segments, zorder=0)\n",
    "    lc.set_array(np.ones(len(y_local)))\n",
    "    lc.set_linewidths(np.full(len(X_local), 0.5))\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.plot(X_local, y_local, 'r.', markersize=5)\n",
    "\n",
    "    plt.plot(X_local, lr.predict(X_local[:, np.newaxis]), 'b-')\n",
    "    plt.gca().add_collection(lc)\n",
    "    plt.legend(('Data', 'Linear Fit'), loc='lower right')\n",
    "    plt.xlabel(feature[0])\n",
    "    plt.ylabel(feature[1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statystyka"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking if every image and sound are present in only one examined, inconsistent pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorted by soundIds\n",
    "pair = data.sort_values(by=['SoundId']) \n",
    "\n",
    "soundids = pd.DataFrame.copy(data)\n",
    "imageids = pd.DataFrame.copy(data)\n",
    "\n",
    "#pair -> image + sound\n",
    "pair.drop_duplicates(subset=['SoundId','ImageId'],keep='first',inplace=True)\n",
    "soundids.drop_duplicates(subset='SoundId',keep='first',inplace=True)\n",
    "imageids.drop_duplicates(subset='ImageId',keep='first',inplace=True)\n",
    "\n",
    "#count uniqe pairs and incentives\n",
    "print(\"Pair count = \", len(pair), \"\\nSounds count = \", len(soundids), \"\\nImages count = \", len(imageids))\n",
    "\n",
    "# if each incentive is in at least one pair, and the number of pairs is equal to the number of incentives,\n",
    "# that means each incentive exists in only one pair - we can identify pair by incentive id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counting means and sds for data from survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_bar(names,values,title):\n",
    "    index = np.arange(len(names))\n",
    "    plt.bar(index, values,color = [(0.2, 0.3, 0.6, 0.5),(0.1, 0.4, 0.6, 0.6),(0.1, 0.5, 0.7, 0.8)])\n",
    "    plt.xlabel('Kind', fontsize = 11)\n",
    "    plt.ylabel('Value', fontsize = 11)\n",
    "    plt.xticks(index, names, fontsize = 9, rotation = 25)\n",
    "    plt.title('Comparing '+title)\n",
    "    plt.show()\n",
    "\n",
    "# get DF with pairs -> image+sound comparing\n",
    "pairs = pd.DataFrame.copy(df_final)\n",
    "#sort by soundIds\n",
    "pairs = pairs.sort_values(by=['SoundId']) \n",
    "\n",
    "####################### Mean #########################\n",
    "\n",
    "# average v for each pair\n",
    "valenceAv =pairs.groupby('SoundId')['valence'].mean()\n",
    "valenceAv = dict(valenceAv)\n",
    "\n",
    "# average a for each pair\n",
    "arousalAv =pairs.groupby('SoundId')['arousal'].mean()\n",
    "arousalAv = dict(arousalAv)\n",
    "\n",
    "# list of sound Ids for random selection\n",
    "soundId_list = list(arousalAv.keys())\n",
    "soundId = random.choice(soundId_list)\n",
    "\n",
    "# example for random test pair\n",
    "df_stat = pd.DataFrame.copy(df_final[['SoundId' , 'ImageId', 'ValMeanPic' , 'ValMeanSound', 'ArMeanPic', 'ArMeanSound']])\n",
    "df_stat.drop_duplicates(subset='SoundId',keep='first',inplace=True)\n",
    "df_stat = df_stat.loc[df_stat['SoundId'] == soundId]\n",
    "df_stat['ArMeanPair'] = arousalAv[soundId]\n",
    "df_stat['ValMeanPair'] = valenceAv[soundId]\n",
    "\n",
    "df_stat = df_stat[['ValMeanPic' , 'ValMeanSound', 'ValMeanPair', 'ArMeanPic', 'ArMeanSound', 'ArMeanPair']]\n",
    "means_names = ['ValMeanPic' , 'ValMeanSound', 'ValMeanPair', 'ArMeanPic', 'ArMeanSound', 'ArMeanPair']\n",
    "means_list = list(df_stat.values.tolist()[0])\n",
    "\n",
    "plot_bar(means_names,means_list,'Means')\n",
    "\n",
    "######################## SD #########################\n",
    "\n",
    "# std v for each pair\n",
    "valenceSd =pairs.groupby('SoundId')['valence'].std()\n",
    "\n",
    "# std a for each pair\n",
    "arousalSd =pairs.groupby('SoundId')['arousal'].std()\n",
    "\n",
    "# prepare SD date for plot purpose\n",
    "df_sd = pd.DataFrame.copy(df_final[['SoundId' , 'ImageId', 'ValSDPic' , 'ValSDSound', 'ArSDPic', 'ArSDSound']])\n",
    "df_sd.drop_duplicates(subset='SoundId',keep='first',inplace=True)\n",
    "df_sd = df_sd.loc[df_sd['SoundId'] == soundId]\n",
    "df_sd['ArSDPair'] = arousalSd[soundId]\n",
    "df_sd['ValSDPair'] = valenceSd[soundId]\n",
    "df_sd = df_sd[['ValSDPic' , 'ValSDSound', 'ValSDPair', 'ArSDPic', 'ArSDSound', 'ArSDPair']].copy()\n",
    "\n",
    "sd_names = ['ValSDPic' , 'ValSDSound', 'ValSDPair', 'ArSDPic', 'ArSDSound', 'ArSDPair']\n",
    "sd_list = list(df_sd.values.tolist()[0])\n",
    "plot_bar(sd_names,sd_list,'SD')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Checking % of data, where negative image/sound made bigger influence for result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pic = data[data['Stimulant'] == 'p+s-']\n",
    "sou = data[data['Stimulant'] == 'p-s+']\n",
    "\n",
    "# get row with negative influence\n",
    "pic_neg = pic[pic['valence'] < 5]\n",
    "sou_neg = sou[sou['valence'] < 5]\n",
    "\n",
    "print(\"Negative feelings/negative picture appeared:\", round(len(sou_neg) / len(sou), 2))\n",
    "print(\"Negative feelings/negative sound appeared:\", round(len(pic_neg) / len(pic), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking % of data, where at least one negative image/sound made bigger influence for result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "have_minus_neg = data_with_minus[data_with_minus['valence'] < 5]\n",
    "print(\"Negative feelings/negative appeared:\", round(len(have_minus_neg) / len(data_with_minus), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking if data is correct for consistence stimulants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_con = data_con.applymap(lambda s : s.replace(',', '.') if isinstance(s, str) else s);\n",
    "data_con = data_con.astype({'arousal' : 'float64','valence' : 'float64'})\n",
    "\n",
    "negative = data_con[data_con['Stimulant'] == 'p-s-']\n",
    "neutral = data_con[data_con['Stimulant'] == 'p0s0']\n",
    "positive = data_con[data_con['Stimulant'] == 'p+s+']\n",
    "\n",
    "# Epislon = 0.15\n",
    "negative_con = negative[negative['valence'] < -0.15]\n",
    "neutral_con = neutral[neutral['valence'] < 0.15]\n",
    "neutral_con = neutral_con[neutral_con['valence'] > -0.15]\n",
    "positive_con = positive[positive['valence'] > 0.15]\n",
    "\n",
    "neg_perc = len(negative_con) / len(negative)\n",
    "neu_perc = len(neutral_con) / len(neutral)\n",
    "pos_perc = len(positive_con) / len(positive)\n",
    "\n",
    "print(\"p-s-: \",neg_perc, \"\\np0s0: \", neu_perc, \"\\np+s+: \", pos_perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
